---
title: '<center>S&P 500: ARMA-GARCH model<center>'
author: "<center>Daniel Herrera<center>"
date: "<center>2023-04-23<center>"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=F, warning=F}
library(fGarch)
library(xts)
library(TSA)
library(rugarch)

```

## Motivation

As you may have noticed, we switched the workflow a bit and are coding in R. Part of data science is knowing the advantages and disadvantages of languages and packages. R is generally highly regarded for statistical analysis; however, here it is very evident as we will be trying to model the S&P 500 using an ARMA(p,q) + GARCH($\tilde{p}$,$\tilde{q}$) process. The package 'rugarch' allows for a very important implementation detail, that the ARMA and GARCH models are fit simultaneously. This is done using quasi-MLE because it allows us to not make a distribution about the distribution of the true error distribution, which is generally made out to be normally distributed. 


## Model Statement 


$X_t = \mu + \sum_{j=1}^{p} \phi_j X_{t-j} + \sum_{j=0}^{q} \theta_j W_{t-j} \\$

$W_t = \sigma_t \varepsilon_t \\$

$\sigma_t^2 = b_0 + \sum_{j=1}^{p_0} b_j W_{t-j}^2 + \sum_{j=1}^{q_0} a_j \sigma_{t-j}^2$

We fit an ARMA(p,q) model onto $X_t$ and then use quasi-MLE to estimate the ARMA and GARCH parameters simultaneously as mentioned previously. 

We see when fitting an AR(1) + GARCH(1,1) that the arch and garch effects are significant p-value < 0.05 for $\alpha_1$ and $\beta_1$. As well, the distribution estimated is the student's t-distribution with 4.9 df, essentially 5. 

```{r}
# laod data
df <- read.csv('spy_returns.csv')


X = diff(log(df$Close))
time_series <- xts(x = X, order.by = as.Date(df$Date[2:length(df$Date)]))

# fit model 
fit = garchFit(~arma(1,0) + garch(1,1), cond.dist = "std", data = X, trace = F)
summary(fit)
```

The resulting model is as follows: 

$$
X_t = \mu + \phi_1 X_{t-1} + W_{t} \\
$$
$$
W_t = \sigma_t \varepsilon_t \\
$$
$$
\sigma_t^2 = \omega + \alpha_1 W_{t-1}^2 + \beta_1 \sigma_{t-1}^2
$$



$$
X_t = 1.017 \times 10^{-3} - 5.407 \times 10^{-2} X_{t-1} +  W_{t} \\
$$
$$
W_t = \sigma_t \varepsilon_t \\
$$
$$
\sigma_t^2 = 2.587 \times 10^{-6} + .1796 W_{t-1}^2 + .809 \sigma_{t-1}^2
$$


## McLeod Li Test

We revisit the McLeod-Li test to quickly check for arch effects to justify our model choice on the time series **after** fitting the AR(1) process. 

Based on the McLeod-Li test, we recall that we would reject the null hypothesis that there are no ARCH effects in the time series and conclude that there are ARCH effects. 

```{r}
McLeod.Li.test(arima(X, order = c(1,0,0)))
```
## Predictions 

Below we notice that we are still predicting 0 for our mean model. This occurs due to the nature of our forecasting process, predicting n steps ahead where n is large and our assumption of a constant mean. Thus, as n increases, our model approaches the Mu as estimated by our fit, which is 0.00099 as shown in the coefficients below. 

```{r}
# test - train split 
train_p= 0.8 

create_split <- function(ts, train_p) {
  train_len = round(length(ts) * train_p)
  train_ts = ts[1:train_len] 
  test_ts = ts[c((train_len + 1):length(ts))]

return(list(train = train_ts, test = test_ts))
}

data_spl = create_split(time_series, 0.8)
train = data_spl$train
test = data_spl$test

# fit the model with training data 
ar1g_fit = garchFit(~arma(1,0) + garch(1,1), cond.dist = "std", data = train, trace = F)
print(summary(ar1g_fit))

# make future fcs
fcst <- predict(ar1g_fit, n.ahead = length(test), plot = T)

```

## Rolling Window (One-Step ahead)

We switch to a more practical approach of using a one-step ahead forecast for $\hat{\sigma}_t$. In essence, we are fitting a series of ARMA + GARCH models to create our forecasts. We first fit our model on the train set, then given the new observed value at time t+1, we fit another model using all previous values until time t+1 to predict time t+2. This seems like the most practical implementation in practice if we wanted to predict these volatilies day to day to create trading strategies. 

The plot below shows the predicted volatility of the test set using the one-step ahead forecast approach and the true returns of the S&P500. We can see how the volatility peaks align closely with the swings in returns of the market and additionally give insight into quieter market periods. 

```{r}
rolling_forecast <- function(y_train, y_test, p_ar, q_ma, p_garch, q_garch) {
  n_test <- length(y_test)
  rolling_preds <- c()
  
  # change back to 1:n_test
  for (i in 1:n_test) {
    # Make special case for initial fcst 
    if (i == 1) {
      train <- y_train
    }
    else{
    train <- c(y_train, y_test[1:(i - 1)])
    }

    # Define the ARMA-GARCH model
    # s is standard garch model 
    # distribution is students t dist
    spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(p_garch, q_garch)),
                       mean.model = list(armaOrder = c(p_ar, q_ma), include.mean = TRUE),
                       distribution.model = "std")
    
    # Fit the model
    model_fit <- ugarchfit(spec, train, solver = "hybrid")
    
    # One step ahead forecast
    pred <- ugarchforecast(model_fit, n.ahead = 1)
    # fitted(pred)[1]
    rolling_preds[i] <- sigma(pred)[1]

  }
  
  # # Convert the predictions to a time-series object with the same index as y_test
  # rolling_preds_ts <- ts(rolling_preds, start = start(y_test), end = end(y_test), frequency = frequency(y_test))
  
  return(rolling_preds)
}
```

```{r}
# Assuming y_train and y_test are your training and testing time-series data
p_ar <- 1
q_ma <- 0
p_garch <- 1
q_garch <- 1

rolling_preds <- rolling_forecast(train, test, p_ar, q_ma, p_garch, q_garch)
```

```{r}
# need to convert rolling preds to ts 
time_index <- time(test)

## Plot the test set
plot(time_index, rolling_preds, type = "l", col = "red", main = "Test Set vs. Rolling Predictions Volatility", xlab = "Time", ylab = "Value", 
     ylim = c(-0.04, 0.04))

# Add the rolling predictions to the existing plot
lines(time(test), test[,1], col = "black")

# Add a legend to the plot
legend("topleft", legend = c("Test Set Log Returns", "Rolling Predictions Volatility"), col = c("black", "red"), lty = 1, bty = "n")
```

We noticed previously that the coefficient for AR(1) of the ARMA(1,0) + GARCH(1,1) model was statistically significant at the alpha 0.001 level (p-value = 0.008). As a result, we decided to see what the expected log returns would be since we would generally expect the prediction in the future of returns to be 0. We notice that when using a rolling window, as done with the volatility, the log returns are only trivially different than 0. One idea, however, is to see the direction that they are moving in and if that lines up with the direction of the test set; that is if the forecast for one day ahead is a positive return, is the test set also positive and likewise for negative.  

```{r}
# convert rolling preds forecast of colatility to log returns (AR)

rolling_forecast_returns <- function(y_train, y_test, p_ar, q_ma, p_garch, q_garch) {
  n_test <- length(y_test)
  rolling_preds <- c()
  
  # change back to 1:n_test
  for (i in 1:n_test) {
    # Make special case for initial fcst 
    if (i == 1) {
      train <- y_train
    }
    else{
    train <- c(y_train, y_test[1:(i - 1)])
    }

    # Define the ARMA-GARCH model
    # s is standard garch model 
    # distribution is students t dist
    spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(p_garch, q_garch)),
                       mean.model = list(armaOrder = c(p_ar, q_ma), include.mean = TRUE),
                       distribution.model = "std")
    
    # Fit the model
    model_fit <- ugarchfit(spec, train, solver = "hybrid")
    
    # One step ahead forecast
    pred <- ugarchforecast(model_fit, n.ahead = 1)
    # 
    rolling_preds[i] <-fitted(pred)[1]
  }
  
  # # Convert the predictions to a time-series object with the same index as y_test
  # rolling_preds_ts <- ts(rolling_preds, start = start(y_test), end = end(y_test), frequency = frequency(y_test))
  
  return(rolling_preds)
}
```

```{r}
rolling_preds_returns <- rolling_forecast_returns(train, test, p_ar, q_ma, p_garch, q_garch)

```


```{r}
# plot of rolling preds log returns vs test set log returns
# need to convert rolling preds to ts 
time_index <- time(test)

## Plot the test set
plot(time_index, rolling_preds_returns, type = "l", col = "red", main = "Test Set vs. Rolling Predictions Log Returns", xlab = "Time", ylab = "Log Return", 
     ylim = c(-0.04, 0.04))

# Add the rolling predictions to the existing plot
lines(time(test), test[,1], col = "black")

# Add a legend to the plot
legend("topleft", legend = c("Test Set Log Returns", "Rolling Predictions Log Returns"), col = c("black", "red"), lty = 1, bty = "n")
```

We see that the accuracy for the correct prediction of the direction of the movement of log returns is 0.56 or 56%. 

```{r}
pos_neg_accuracy <- function(vec1, vec2) {
  # check that lengths are equal
  if (length(vec1) != length(vec2)) {
    stop("The input vectors must have the same length.")
  }
  
  vec_length <- length(vec1)
  
  # Check if both elements at the same position are positive or negative
  same_sign <- (vec1 > 0 & vec2 > 0) | (vec1 < 0 & vec2 < 0)
  
  # Calculate the accuracy
  accuracy <- sum(same_sign) / vec_length
  
  return(accuracy)
}

pos_neg_accuracy(test, rolling_preds_returns)
```

